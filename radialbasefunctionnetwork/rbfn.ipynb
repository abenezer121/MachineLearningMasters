{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['variance' 'skewness' 'curtosis' 'entropy' 'class']\n"
     ]
    }
   ],
   "source": [
    "# read the dataset\n",
    "trainingdata = pd.read_csv('./dataset/banknote.csv')\n",
    "labels = trainingdata.columns.values\n",
    "print(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "# separate the column and the row\n",
    "def scale_dataset(dataframe, oversample=False):\n",
    "    X = dataframe[dataframe.columns[:-1]].values\n",
    "    Y = dataframe[dataframe.columns[-1]].values\n",
    "\n",
    "    scalar = StandardScaler()\n",
    "    # take x and fit the scalar transform all the values\n",
    "    X = scalar.fit_transform(X)\n",
    "    # if one dataset is way much higher than the other one this will make the model to prefer the data with higher number of class\n",
    "    # so we make the data equal\n",
    "    if oversample:\n",
    "        ros = RandomOverSampler()\n",
    "        X, Y = ros.fit_resample(X, Y)\n",
    "\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# scale and normalize the data\n",
    "xtrain, ytrain = scale_dataset(trainingdata, oversample=True)\n",
    "Xtrain,  Ytrain, Xtest, Ytest = train_test_split(xtrain, ytrain,  random_state=104,\n",
    "                                                 test_size=0.25,\n",
    "                                                 shuffle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RBFNN:\n",
    "\n",
    "    def __init__(self, kernels, centers, beta=0.1, lr=0.1, epochs=80) -> None:\n",
    "\n",
    "        self.kernels = kernels\n",
    "        self.centers = centers\n",
    "        self.beta = beta\n",
    "        self.lr = lr\n",
    "        self.epochs = epochs\n",
    "        self.b = np.random.randn(1, 1)\n",
    "        self.W = np.random.randn(kernels, 1)\n",
    "       \n",
    "\n",
    "      \n",
    "\n",
    "        # to save the gradients calculated by the network\n",
    "   \n",
    "        self.gradients = []\n",
    "\n",
    "    def rbf_activation(self, x, center):\n",
    "        return np.exp(-self.beta*np.linalg.norm(x - center)**2)\n",
    "\n",
    "    def linear_activation(self, A):\n",
    "        return self.W.T.dot(A) + self.b\n",
    "\n",
    "    def least_square_error(self, pred, y):\n",
    "        return (y - pred).flatten()**2\n",
    "\n",
    "    def _forward_propagation(self, x):\n",
    "\n",
    "        a1 = np.array([\n",
    "            [self.rbf_activation(x, center)]\n",
    "            for center in self.centers\n",
    "        ])\n",
    "\n",
    "        a2 = self.linear_activation(a1)\n",
    "\n",
    "        return a2, a1\n",
    "\n",
    "    def _backpropagation(self, y, pred, a1):\n",
    "        # Back propagation\n",
    "        dW = -(y - pred).flatten()*a1\n",
    "        db = -(y - pred).flatten()\n",
    "\n",
    "        # Updating the weights\n",
    "        self.W = self.W - self.lr*dW\n",
    "        self.b = self.b - self.lr*db\n",
    "        return dW, db\n",
    "\n",
    "    def fit(self, X, Y):\n",
    "\n",
    "        for _ in range(self.epochs):\n",
    "\n",
    "            for x, y in list(zip(X, Y)):\n",
    "                # Forward propagation\n",
    "                pred, a1 = self._forward_propagation(x)\n",
    "\n",
    "                error = self.least_square_error(pred[0], y[0, np.newaxis])\n",
    "                \n",
    "\n",
    "                # Back propagation\n",
    "                dW, db = self._backpropagation(y, pred, a1)\n",
    "                self.gradients.append((dW, db))\n",
    "\n",
    "    def predict(self, x):\n",
    "        a2, a1 = self._forward_propagation(x)\n",
    "        \n",
    "        return np.squeeze(a2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start predicting\n",
      " accuracy 76.9028871391076 \n"
     ]
    }
   ],
   "source": [
    "Xtest = Xtest.reshape(len(Xtest), 1)\n",
    "Ytest = Ytest.reshape(len(Ytest), 1)\n",
    "\n",
    "rbf = RBFNN(kernels=2,\n",
    "                centers=np.array([\n",
    "                    [0, 1 ,0 ,1],\n",
    "                    [1, 0 ,1 , 0]\n",
    "\n",
    "                ]),\n",
    "                beta=0.31,\n",
    "                lr=0.01,\n",
    "                epochs=100\n",
    "                )\n",
    "\n",
    "rbf.fit(Xtrain, Xtest)\n",
    "\n",
    "\n",
    "num_correct = 0\n",
    "\n",
    "print(\"start predicting\")\n",
    "\n",
    "for i in range(len(Ytrain)):\n",
    "    pred = rbf.predict(Ytrain[i])\n",
    "    p = 1 if pred > 0.5 else 0\n",
    "    \n",
    "    if p == Ytest[i]:\n",
    "         num_correct += 1\n",
    "   \n",
    "print(f' accuracy {(num_correct / len(Ytest)) * 100 } ')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9 (tags/v3.10.9:1dd9be6, Dec  6 2022, 20:01:21) [MSC v.1934 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1af9bccfc8dc720bdb4344246e512a802194bbd2352e86f7c49a1ad9815e25fb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
