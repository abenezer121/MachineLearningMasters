{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import idx2numpy\n",
    "import cv2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "\n",
    "# loading train images and test labels\n",
    "# trainimage is 60000 ,28 , 28 shape\n",
    "imagetrain = idx2numpy.convert_from_file('./dataset/train-images.idx3-ubyte')\n",
    "imagetrainlabel = idx2numpy.convert_from_file(\n",
    "    './dataset/train-labels.idx1-ubyte')\n",
    "\n",
    "# loding test images and test labels\n",
    "imagetest = idx2numpy.convert_from_file('./dataset/test-images.idx3-ubyte')\n",
    "imagetestlable = idx2numpy.convert_from_file(\n",
    "    './dataset/test-labels.idx1-ubyte')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_eucludian(vec1, vec2):\n",
    "    return np.sqrt(np.sum((vec1-vec2)**2))\n",
    "\n",
    "\n",
    "def predict_label_index(test, imagetrain):\n",
    "    distances = []\n",
    "    for i in range(len(imagetrain)):\n",
    "        distances.append(calculate_eucludian(test, imagetrain[i]))\n",
    "\n",
    "    # sort the distances array using numpy argsort to preserve the original index\n",
    "    # and take 1 from the sorted\n",
    "    indices = np.argsort(distances)[:1]\n",
    "\n",
    "    return imagetrainlabel[indices[0]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get each numbers from image using opencv\n",
    "\n",
    "# Set image path\n",
    "\n",
    "fileName = \"c.jpg\"\n",
    "\n",
    "# Read input image:\n",
    "inputImage = cv2.imread(fileName)\n",
    "inputCopy = inputImage.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert BGR to grayscale:\n",
    "grayscaleImage = cv2.cvtColor(inputImage, cv2.COLOR_BGR2GRAY)\n",
    "# adaptive thereshould parameter to separate the foreground image from the background\n",
    "windowSize = 43\n",
    "windowConstant = -1\n",
    "# Apply the threshold:\n",
    "binaryImage = cv2.adaptiveThreshold(\n",
    "    grayscaleImage, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, windowSize, windowConstant)\n",
    "\n",
    "\n",
    "# Perform an area filter on the binary blobs:\n",
    "componentsNumber, labeledImage, componentStats, componentCentroids = cv2.connectedComponentsWithStats(\n",
    "    binaryImage, connectivity=4)\n",
    "\n",
    "# Set the minimum pixels for the area filter:\n",
    "minArea = 43\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the indices/labels of the remaining components based on the area stat\n",
    "# (skip the background component at index 0)\n",
    "remainingComponentLabels = [i for i in range(\n",
    "    1, componentsNumber) if componentStats[i][4] >= minArea]\n",
    "\n",
    "# Filter the labeled pixels based on the remaining labels,\n",
    "# assign pixel intensity to 255 (uint8) for the remaining pixels\n",
    "filteredImage = np.where(\n",
    "    np.isin(labeledImage, remainingComponentLabels) == True, 255, 0).astype('uint8')\n",
    "\n",
    "\n",
    "# Set kernel (structuring element) size:\n",
    "kernelSize = 3\n",
    "\n",
    "# Set operation iterations:\n",
    "opIterations = 1\n",
    "\n",
    "# Get the structuring element:\n",
    "maxKernel = cv2.getStructuringElement(cv2.MORPH_RECT, (kernelSize, kernelSize))\n",
    "\n",
    "# Perform closing:\n",
    "closingImage = cv2.morphologyEx(\n",
    "    filteredImage, cv2.MORPH_CLOSE, maxKernel, None, None, opIterations, cv2.BORDER_REFLECT101)\n",
    "\n",
    "\n",
    "# Get each bounding box\n",
    "# Find the big contours/blobs on the filtered image:\n",
    "contours, hierarchy = cv2.findContours(\n",
    "    closingImage, cv2.RETR_CCOMP, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "contours_poly = [None] * len(contours)\n",
    "# The Bounding Rectangles will be stored here:\n",
    "boundRect = []\n",
    "\n",
    "# Alright, just look for the outer bounding boxes:\n",
    "for i, c in enumerate(contours):\n",
    "\n",
    "    if hierarchy[0][i][3] == -1:\n",
    "        contours_poly[i] = cv2.approxPolyDP(c, 3, True)\n",
    "        boundRect.append(cv2.boundingRect(contours_poly[i]))\n",
    "\n",
    "\n",
    "# Draw the bounding boxes on the (copied) input image:\n",
    "for i in range(len(boundRect)):\n",
    "    color = (0, 255, 0)\n",
    "    cv2.rectangle(inputCopy, (int(boundRect[i][0]), int(boundRect[i][1])),\n",
    "                  (int(boundRect[i][0] + boundRect[i][2]), int(boundRect[i][1] + boundRect[i][3])), color, 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 6, 4, 0, 2, 5, 4, 4, 1, 4, 0, 1, 4, 2, 7, 4, 1]\n"
     ]
    }
   ],
   "source": [
    "arr = []\n",
    "# Crop the characters:\n",
    "for i in range(len(boundRect)):\n",
    "    # Get the roi for each bounding rectangle:\n",
    "    x, y, w, h = boundRect[i]\n",
    "    # Crop the roi:\n",
    "    croppedImg = closingImage[y:y + h, x:x + w]\n",
    "    # resshape the image into 28 , 28 to match the training set\n",
    "    reshappedimage = cv2.resize(croppedImg , (28,28))\n",
    "    arr.append(predict_label_index(reshappedimage, imagetrain))\n",
    "    \n",
    "print(arr)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1af9bccfc8dc720bdb4344246e512a802194bbd2352e86f7c49a1ad9815e25fb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
